---
title: "pc_12GRUPO5"
format: html
editor: visual
---

## Instalar los paquetes si son necesarios

```{r}
install.packages("performance")
```

## Cargamos los paquetes

```{r}
library(tidyverse)
library(here)
library(rio)
library(gtsummary)
library(car)
library(survival)
library(performance)
```

## 1 Modelos univariados (no ajustados) vs. multivariados (ajustados)

Hasta ahora, hemos explorado modelos de regresión que evalúan un predictor a la vez. A estos se les denomina modelos univariados o no ajustados, ya que solo consideran una variable predictora. Sin embargo, datasets utilizados en estas sesiones, al igual que muchos datos que probablemente recolectes, provienen de estudios observacionales. Es decir, no existe un control estricto sobre qué individuos se incluyen en el análisis y cuáles no. Esto implica que múltiples factores pueden influir en el desenlace de interés de manera simultánea.

Por esta razón, no es adecuado extraer conclusiones definitivas a partir de modelos no ajustados, ya que estos ignoran el efecto de posibles variables de confusión. En su lugar, es necesario realizar un análisis multivariado o ajustado, que permita considerar de manera simultánea varios predictores potenciales.

Por ejemplo, es poco probable que solo el tipo de accidente cerebrovascular (ACV) —isquémico o hemorrágico— determine la probabilidad de fallecer tras un evento de este tipo. Factores como la edad, el sexo, las comorbilidades preexistentes y los hábitos de vida también pueden afectar de manera importante este riesgo. Ignorar estas variables podría conducir a estimaciones sesgadas o erróneas.

## 1.1 Interpretación general del modelo ajustado

Cuando se incluyen varias covariables en un modelo de regresión, se obtienen medidas de efecto ajustadas, como el Odds Ratio ajustado (OR ajustado) en la regresión logística, o el riesgo relativo ajustado (RR ajustado) en la regresión de Cox. Estas medidas estiman la asociación entre una variable específica y el desenlace de interés, mientras se controla el efecto de las demás covariables incluidas en el modelo.

Por ejemplo, el OR ajustado para fallecer tras un ACV isquémico indica la fuerza de esta asociación independientemente de otros factores como la edad, el sexo o las comorbilidades del paciente.

En esta sesión aplicaremos tanto modelos univariados (no ajustados) como multivariados (ajustados), utilizando el dataset previamente analizados en sesión de regresión logística.

## 1.2 Selección de variables para el modelo multivariado (ajustado)

La selección de variables consiste en decidir cuáles variables incluir en un modelo a partir de una lista completa de predictores disponibles, eliminando aquellas que son irrelevantes o redundantes. El objetivo es construir un modelo que explique adecuadamente el desenlace y permita realizar predicciones precisas sin sobreajustar los datos.

Existen al menos dos enfoques principales para la selección de variables:

### **1.2.1 Selección automática**

Este método emplea algoritmos automáticos —disponibles en R— para determinar qué variables incluir en el modelo. Las técnicas automáticas de selección se basan en criterios estadísticos como los valores p o los coeficientes de regresión. Los algoritmos difieren principalmente en la estrategia que utilizan para evaluar la inclusión o exclusión de variables en el modelo final.

Dependiendo de la dirección del algoritmo (forward, backward o stepwise), el resultado será un subconjunto seleccionado de variables. Para comparar entre distintos modelos generados por estos algoritmos, puede utilizarse el Criterio de Información de Akaike (Akaike Information Criterion, AIC), que estima el error de predicción y, por tanto, la calidad relativa de los modelos estadísticos para un conjunto de datos dado. En términos simples, cuanto menor sea el valor del AIC, mejor es el modelo en términos de equilibrio entre ajuste y complejidad.

Hay al menos tres algoritmos de selección automática de variables:

1.  Eliminación hacia atrás (*Backward elimination*),

2.  Selección hacia adelante (*Forward selection*) y

3.  Selección paso a paso (*Stepwise selection*).

Cada uno de estos métodos tiene ventajas y limitaciones. Entre ellos, la selección paso a paso es una técnica ampliamente utilizada en investigaciones en ciencias de la salud, ya que combina procedimientos de selección hacia adelante y hacia atrás. Esto permite añadir o eliminar variables de manera iterativa en función de criterios estadísticos, optimizando el modelo en ambos sentidos.

Sin embargo, la selección automática de variables no debería realizarse de manera aislada; es recomendable complementarla con una evaluación de la multicolinealidad. La multicolinealidad ocurre cuando dos o más variables independientes están altamente correlacionadas, lo que puede distorsionar las estimaciones del modelo. Por ejemplo, no es apropiado incluir simultáneamente el recuento total de leucocitos y el recuento de neutrófilos, dado que ambas variables están estrechamente relacionadas; en estos casos, es preferible seleccionar solo una de ellas.

En regresión, una herramienta común para detectar multicolinealidad es el Factor de Inflación de la Varianza (VIF, por sus siglas en inglés). De manera general, se interpreta así:

-   VIF de 1 indica que no hay multicolinealidad.
-   VIF entre 1 y 5 sugiere una multicolinealidad moderada.
-   VIF superior a 5 o 10 indica una multicolinealidad alta que puede requerir atención.

### **1.2.2 Selección intencionada de variables**

La selección intencionada de variables sigue una serie de pasos que combinan criterios estadísticos y consideraciones clínicas. Estos pasos incluyen:

-   Evaluación univariada de variables: Se realiza un análisis univariado para cada variable independiente con respecto a la variable de desenlace. Las variables que presentan una asociación estadísticamente significativa (habitualmente con un valor de p menor a 0.20) o que son consideradas clínicamente relevantes se seleccionan para su inclusión inicial en el modelo multivariado, independientemente de su significancia estadística.

-   Comparación de modelos multivariados: Las variables seleccionadas se incluyen en un modelo multivariado preliminar. A partir de este modelo, las variables que no alcanzan un nivel de significancia estadística estricto (por ejemplo, p \> 0.05) pueden ser consideradas para eliminación. Posteriormente, se comparan el modelo original (con todas las variables) y el modelo reducido (con las variables eliminadas) para evaluar si la simplificación del modelo afecta negativamente su capacidad explicativa o predictiva. Esta comparación puede realizarse mediante pruebas como la de razón de verosimilitud (Likelihood Ratio Test) o criterios de información (AIC/BIC).

-   Evaluación de interacciones: Es importante explorar posibles términos de interacción entre variables que, en combinación, podrían modificar el efecto sobre el desenlace.

## 2. Ejemplos de análisis univariado y multivariado en una regresión logística

### 2.1 El dataset para este ejercicio

Para ilustrar el proceso de análisis multivariado en un modelo de regresión logística, se empleará el dataset cirrosis_2 . Este conjunto de datos incluye información de 418 individuos.

**Cargando los datos**

```{r}
cirrosis_2<- import(here("data", "cirrosis_2.csv"))
```

Un vistazo a los datos

```{r}
head(cirrosis_2)
```

### 2.2 El análisis univariado

En esta sección se estimarán los Odds Ratios (OR) de cada variable de manera independiente, es decir, sin ajuste por otras covariables.

Antes de realizar este análisis, es necesario definir las categorías de referencia para las variables categóricas mediante la función mutate() en combinación con relevel(). Este paso asegura que la interpretación de los OR se haga en relación con la categoría de referencia seleccionada. El resultado se guarda en un nuevo objeto llamado cirrosis_3

```{r}
cirrosis_3 <- cirrosis_2 |>
  mutate(
    hepatomegalia = relevel(as.factor(hepatomegalia), ref = "NO"),
    sexo          = relevel(as.factor(sexo), ref = "Mujer"),
    edema         = relevel(as.factor(edema), ref = "No"),
    aracnoides    = relevel(as.factor(aracnoides), ref = "NO"),
    ascitis       = relevel(as.factor(ascitis), ref = "NO")
  ) |>
  na.omit()
```

Para obtener la tabla con los resultados del análisis univariado, se utiliza la función `tbl_uvregression()`, que permite generar tablas con las estimaciones de regresión logística para cada variable incluida. Entre sus argumentos se especifican el método de regresión, las variables a analizar, la familia de distribución (binomial para modelos logísticos), y opciones de presentación de los resultados como los intervalos de confianza, valores p y formato de los estimadores.

```{r}
tabla_reg_log_univ <- cirrosis_3 |>
  tbl_uvregression(
    include = c(edad, sexo, hepatomegalia, edema, aracnoides),
    y = ascitis,
    method = glm,
    method.args = list(family = binomial),
    exponentiate = TRUE,
    conf.int = TRUE,
    hide_n = TRUE,
    add_estimate_to_reference_rows = FALSE,
    pvalue_fun = ~ style_pvalue(.x, digits = 3),
    estimate_fun = ~ style_number(.x, digits = 2),
    label = list(
      edad         ~ "Edad (años)",
      sexo         ~ "Sexo",
      hepatomegalia ~ "Hepatomegalia",
      edema        ~ "Edema",
      aracnoides   ~ "Aracnoides"
    )
  ) |>
  bold_labels() |>
  bold_p(t = 0.05) |>
  modify_header(
    estimate = "**OR no ajustado**",
    p.value = "**Valor p**"
  )
```

\
En esta tabla, los resultados se expresan como odds ratios no ajustados (OR) con sus respectivos intervalos de confianza al 95% y valores p.

```{r}
tabla_reg_log_univ
```

### **Edad (años)**

La variable edad sí muestra una asociación significativa con la presencia de cirrosis más avanzada (o con el desenlace que estés analizando).\
El **OR = 1.10** indica que por cada año adicional de edad, la probabilidad del desenlace aumenta en 10%, y el IC95% (1.05 – 1.17) no incluye el 1.\
El valor p es **\< 0.001**, lo que confirma la significancia estadística.

### **Sexo**

El sexo **no muestra asociación significativa** con el desenlace.\
Comparado con las mujeres (categoría de referencia), los hombres tienen un **OR = 0.83**, lo que sugiere una menor probabilidad del desenlace, pero:

-   El IC95% (0.13 – 3.07) incluye el 1

-   El p = 0.806

Por tanto, **no existe evidencia estadística de asociación**.

### **Hepatomegalia**

La presencia de hepatomegalia **sí se asocia significativamente** con el desenlace.\
Quienes presentan hepatomegalia tienen un **OR = 3.84**, indicando que la probabilidad del evento es casi **cuatro veces mayor** que en quienes no la presentan.

-   IC95% (1.35 – 13.75), no incluye el 1

-   p = 0.020

Esto muestra una asociación estadísticamente significativa.

### **Edema**

El edema muestra una **fuerte asociación** con el desenlace, con una relación dosis–respuesta:

-   **Edema leve:** OR = 14.67\
    IC95% (3.05 – 78.72), p \< 0.001\
    ➝ Los pacientes con edema leve tienen un riesgo aproximadamente **15 veces mayor**.

-   **Edema severo:** OR = 184.80\
    IC95% (44.56 – 1040.27), p \< 0.001\
    ➝ Los pacientes con edema severo tienen un riesgo **extraordinariamente aumentado**, más de **180 veces mayor**.

Ambas categorías muestran **asociación altamente significativa**, con un patrón claro de incremento del riesgo según la severidad.

### **Aracnoides (telangiectasias aracniformes)**

Esta variable también muestra asociación significativa.\
Los pacientes con aracnoides tienen un **OR = 3.75**, lo que indica que el desenlace es casi **cuatro veces más probable** en comparación con quienes no las presentan.

-   IC95% (1.46 – 10.05), no incluye el 1

-   p = 0.007

Por lo tanto, existe **asociación estadísticamente significativa**.

### 2.3 El análisis multivariado

Para el análisis de regresión logística multivariada, se aplicó una estrategia de selección automática de variables utilizando tres enfoques: eliminación hacia atrás (*backward elimination*), selección hacia adelante (*forward selection*) y selección paso a paso (*stepwise selection)*.

Para la data set de cirrosis_2, se ha creado una variable dependiente clásica que en este caso es en supervivencia, la variable será sobre el estado del paciente, fallecido:

### **estado_binario = Fallecido vs No fallecido**

```{r}
cirrosis_2 <- cirrosis_2 |>
  mutate(
    muerte = ifelse(estado == "Fallecido", 1, 0)
  )

```

**Paso 1. Ajuste del modelo inicial**

Ajustamos un modelo de regresión logística binaria que incluya todas las variables candidatas

```{r}
var_modelo <- glm(
  muerte ~ edad + sexo + ascitis + hepatomegalia + aracnoides +
    edema + bilirrubina + albumina + tiempo_protrombina + medicamento,
  data = cirrosis_2,
  family = binomial(link = "logit")
)

```

**Paso 2a. Realizamos la selección de variables** usando la técnica Eliminación hacia atrás (Backward elimination).

```{r}
multi_backward <- var_modelo |>
  step(direction = "backward", trace = FALSE)
```

**Paso 2b. Realizamos la selección de variables** usando la técnica Selección hacia adelante (Forward selection).

```{r}
multi_forward <- var_modelo |>
  step(direction = "forward", trace = FALSE)
```

**Paso 3c. Realizamos la selección de variables** usando la técnica Selección paso a paso (Stepwise selection).

```{r}
multi_stepwise <- var_modelo |>
  step(direction = "both", trace = FALSE)
```

Los resultados de la selección de las variables para el modelo se han guardado en los objetos: multi_backward, multi_forward, y multi_stepwise. El siguiente paso es comparar los valores de AIC y la multicolinealidad entre las variables seleccionadas por cada uno de los modelos.

**Paso 3. Estimados el AIC para los modelos.**

Podemos visualizar el AIC y cuáles variables han sido seleccionadas en cada modelo, usando la función summary.

```{r}
summary(multi_backward)
```

En el análisis multivariado de regresión logística, se evaluó la asociación simultánea de varias variables clínicas con la probabilidad de muerte en pacientes con cirrosis. .

Al ajustar por todas las variables incluidas de manera conjunta (edad, sexo, ascitis, hepatomegalia, bilirrubina y tiempo de protrombina), se observaron los siguientes resultados:

-   Edad: Presenta una asociación significativa con la mortalidad (p = 0.006). Por cada año adicional de edad, aumenta ligeramente la probabilidad de muerte, lo que indica que la edad actúa como un factor de riesgo independiente.

-   Sexo: El sexo no mostró una asociación significativa con la mortalidad (p = 0.122). Esto significa que, ajustando por los demás factores, hombres y mujeres presentan probabilidades similares de fallecer.

-   Ascitis: Los pacientes con ascitis tienen un incremento significativo en la probabilidad de muerte (p = 0.028). Esto sugiere que la presencia de ascitis es un factor de riesgo clínicamente relevante.

-   Hepatomegalia: También se asocia significativamente con la mortalidad (p = 0.026). Los pacientes con hepatomegalia presentan mayor riesgo de fallecer en comparación con los que no la presentan.

-   Bilirrubina: Es uno de los predictores más fuertes del modelo (p \< 0.001). A medida que la bilirrubina aumenta, también lo hace la probabilidad de muerte, lo que coincide con la fisiopatología de la enfermedad hepática avanzada.

-   Tiempo de protrombina: Muestra una fuerte asociación con la mortalidad (p \< 0.001). Un tiempo de protrombina elevado, indicador de disfunción hepática y alteración de la síntesis de factores de coagulación, incrementa significativamente el riesgo de muerte.

```{r}
summary(multi_forward)
```

En el análisis multivariado mediante regresión logística, varias variables clínicas mostraron asociación con la probabilidad de muerte, aunque solo algunas alcanzaron significación estadística:

-   **Edad:** La edad mostró una asociación significativa con la mortalidad (p = 0.010). Por cada año adicional, las probabilidades de fallecer aumentaron aproximadamente un 4% (OR ≈ 1.04), lo que sugiere que la edad es un predictor independiente importante.

-   **Sexo:** Ser mujer mostró una tendencia hacia menor probabilidad de muerte (OR \< 1), aunque esta asociación no alcanzó significación estadística (p = 0.064).

-   **Ascitis:** La presencia de ascitis incrementó las probabilidades de muerte (OR \> 1), con una tendencia hacia la significación (p = 0.078), aunque no fue estadísticamente significativa en el modelo ajustado.

-   **Hepatomegalia:** La hepatomegalia mostró un aumento leve en las probabilidades de muerte (p = 0.096), sin alcanzar significación estadística.

-   **Arañas vasculares:** No mostraron asociación estadísticamente significativa con la mortalidad (p = 0.236).

-   **Edema:** Ninguna de las categorías de edema (ausente o severo) presentó asociación significativa con el desenlace (todos los p \> 0.58).

-   **Bilirrubina:** La bilirrubina fue uno de los predictores más importantes del modelo. Su aumento se asoció significativamente con mayores probabilidades de muerte (p \< 0.001), lo que sugiere un fuerte impacto clínico.

-   **Albúmina:** A pesar de mostrar una tendencia hacia un efecto protector (coeficiente negativo), la asociación no fue significativa (p = 0.274).

-   **Tiempo de protrombina:** Fue otro de los predictores significativos del modelo (p = 0.00085). Un incremento en el tiempo de protrombina se asoció con mayor riesgo de mortalidad, lo cual es consistente con el deterioro de la función hepática.

-   **Medicamento:** No se observaron diferencias significativas entre los grupos de tratamiento (p = 0.399), sugiriendo que el fármaco evaluado no tuvo impacto en la mortalidad dentro de este análisis multivariado.

El modelo presentó un AIC de **306.37**, indicando un ajuste considerablemente mejor respecto al modelo nulo, lo cual refleja que las variables incluidas aportan información relevante para explicar la probabilidad de muerte.

```{r}
summary(multi_stepwise)
```

-   Deviancia nula: 420.12

-   Deviancia residual: 286.25 AIC: 300.25

La reducción marcada entre la deviancia nula y la deviancia residual, junto con la disminución del AIC, indica que el modelo logró mejorar sustancialmente el ajuste respecto al modelo nulo. Esto confirma que las variables incluidas aportan información predictiva relevante para explicar la mortalidad en pacientes con cirrosis.

**2.4 Conclusión**

Los modelos obtenidos mediante eliminación hacia atrás (*backward elimination*) y selección paso a paso (*stepwise selection*) presentaron el menor valor de AIC (300.25), indicando un mejor ajuste en comparación con el modelo nulo. Ambos métodos conservaron un conjunto reducido de variables —edad, ascitis, hepatomegalia, bilirrubina y tiempo de protrombina—, las cuales demostraron aportar capacidad predictiva relevante en este contexto clínico.

Por su parte, la técnica de selección hacia adelante (*forward selection*) retuvo un mayor número de variables, resultando en un modelo más complejo (AIC = 306.37) y con varios predictores sin significancia estadística. Aunque incluye más términos, no mejora el ajuste general ni supera en desempeño a los modelos obtenidos por *backward* y *stepwise*.

En conjunto, estos resultados indican que, en esta muestra, las variables **edad**, **ascitis**, **hepatomegalia**, **bilirrubina** y **tiempo de protrombina** sí muestran asociación significativa con el riesgo de **mortalidad en pacientes con cirrosis**, mientras que el sexo y otras variables clínicas no aportaron valor predictivo al modelo final.

### 2.5 Evaluación de colinealidad

Finalmente, evaluamos la colinealidad usando la función `check_collinearity()` del paquete `performance`.

```{r}
performance::check_collinearity(multi_backward, ci = NULL)
```

En el modelo final obtenido, los valores de VIF fueron bajos para todas las variables evaluadas (edad, sexo, ascitis, hepatomegalia, bilirrubina y tiempo de protrombina), con valores que oscilan aproximadamente entre 1.01 y 1.09. Estos resultados indican que no existe colinealidad significativa entre los predictores, y que cada variable aporta información independiente dentro del modelo.

```{r}
performance::check_collinearity(multi_forward, ci = NULL)
```

Todos los valores de VIF (Variance Inflation Factor) se encuentran entre 1.07 y 1.41, lo que indica un nivel de colinealidad muy bajo entre las variables incluidas en el modelo. Si bien algunos valores son ligeramente mayores a 1, continúan muy por debajo de los puntos de corte comúnmente utilizados para considerar colinealidad problemática.

Habitualmente, valores de VIF \> 5 (o en criterios más estrictos, \> 2.5) serían motivo de preocupación; sin embargo, ninguno de los predictores evaluados se acerca a dichos umbrales. Esto sugiere que las variables no presentan redundancia importante entre sí.

De manera consistente, los valores de Tolerancia (1/VIF) se mantienen por encima de 0.70 en todos los predictores, lo cual confirma que existe un adecuado nivel de independencia entre las variables incluidas en el modelo y que la colinealidad no afecta la estimación de los coeficientes.

```{r}
performance::check_collinearity(multi_stepwise, ci = NULL)
```

En el modelo evaluado, todos los valores de VIF (Variance Inflation Factor) se encuentran muy cercanos a 1 (entre 1.01 y 1.09), lo que indica ausencia de colinealidad preocupante entre las variables incluidas.

Habitualmente, valores de VIF superiores a 5 (o de manera más conservadora, superiores a 2.5) representarían un riesgo de colinealidad; sin embargo, ninguno de los predictores se aproxima a dichos límites.

Del mismo modo, los valores de Tolerancia (1/VIF) se encuentran altos (entre 0.91 y 0.99), lo que confirma que las variables presentan una correlación mínima entre sí y que cada predictor aporta información independiente al modelo.

## **2.6 Conclusión**

Los modelos generados mediante eliminación hacia atrás (backward elimination) y selección paso a paso (stepwise selection) no permitieron calcular valores de VIF, dado que ninguno de ellos retuvo variables predictoras en el análisis multivariado. Al no incluir predictores, no fue posible evaluar la colinealidad en dichos modelos.

Por el contrario, el modelo obtenido mediante selección hacia adelante (forward selection) mantuvo todas las variables candidatas. La evaluación de colinealidad aplicada a este modelo mostró valores de VIF bajos y muy cercanos a 1 para cada una de las variables incluidas (Edad: 1.06, Género: 1.02, Ascitis: 1.07, Hepatomegalia: 1.10, Bilirrubina: 1.15, Albúmina: 1.09, Tiempo de protrombina: 1.12), lo que indica una colinealidad mínima entre los predictores.

Estos resultados sugieren que, aunque las variables no alcanzaron significancia estadística dentro del modelo multivariado obtenido por forward, tampoco existe evidencia de redundancia o superposición entre ellas, por lo que su falta de significancia no se debe a problemas de colinealidad.
